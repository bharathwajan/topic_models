{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bay=pd.read_csv(\"../nb_outputs/news_20/baysian_topic_5.csv\")\n",
    "bay.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "\n",
    "plsa_5top=pd.read_csv(\"../plsa_outputs/news_20/5_topics.csv\")\n",
    "plsa_5top.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../nb_outputs/news_20/missing_values_5.pkl\",\"rb\") as f:\n",
    "    missed_idx=pickle.load(f) #got this from nb_gnn \n",
    "# missed_idx #drop these values from plsa  #these are the index which are not in the baysian_topic_5 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 3) 18846\n",
      "18846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10743, (10743, 5))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_20=pd.read_csv(\"../datasets/20news.csv\")\n",
    "print(news_20.shape,bay.shape[0]+len(missed_idx))\n",
    "#now using this information generate new indexes\n",
    "#from the original subtract(eliminate) the missing idx and the new idx \n",
    "original_idx=list(range(news_20.shape[0]))\n",
    "print(len(original_idx))\n",
    "for item in missed_idx:\n",
    "    original_idx.remove(item)\n",
    "len(original_idx),bay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column in bayes and append these indexes\n",
    "bay[\"index\"]=original_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now remove the rows which was not common to both the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_idx,plsa_5top_idx=set(bay[\"index\"]),set(plsa_5top[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_keep=bay_idx.intersection(plsa_5top_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10736"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_bay=bay[bay[\"index\"].isin(idx_to_keep)]\n",
    "cleaned_plsa_5=plsa_5top[plsa_5top[\"index\"].isin(idx_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cleaned_plsa_5[\"index\"].to_list()\n",
    "for i in cleaned_bay[\"index\"].to_list():\n",
    "    if i not in temp:\n",
    "        print(i,\"what the fuck\")\n",
    "    # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding match accuracy without order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics: 5\n",
      "n largest : 3\n",
      "Threshold is : 60\n",
      "read sucessfully\n",
      "accuracy : 0 % \n",
      "result already shown\n",
      "topics: 5\n",
      "n largest : 3\n",
      "Threshold is : 80\n",
      "read sucessfully\n",
      "accuracy : 0 % \n",
      "result already shown\n",
      "topics: 5\n",
      "n largest : 3\n",
      "Threshold is : 100\n",
      "read sucessfully\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'thres_80.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32md:\\PG\\3rd sem\\Thesis\\sem_4_coding\\match_finder\\match_finder.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mn largest :\u001b[39m\u001b[39m\"\u001b[39m,n_largest)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThreshold is :\u001b[39m\u001b[39m\"\u001b[39m,threshold)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m accuracy(n_largest,threshold)\n",
      "\u001b[1;32md:\\PG\\3rd sem\\Thesis\\sem_4_coding\\match_finder\\match_finder.ipynb Cell 12\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(n_largest, match_threshold)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m decision\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m decision\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m decision\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYES\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     file_name\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39menter file name :\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     result\u001b[39m.\u001b[39;49mto_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile_name\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/PG/3rd%20sem/Thesis/sem_4_coding/match_finder/match_finder.ipynb#W0sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39mmatch\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()[\u001b[39mTrue\u001b[39;00m]\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\core\\generic.py:3721\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3710\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3712\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3713\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3714\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3718\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3719\u001b[0m )\n\u001b[1;32m-> 3721\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3722\u001b[0m     path_or_buf,\n\u001b[0;32m   3723\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3724\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3725\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3726\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3727\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3728\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3729\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3730\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3731\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3732\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3733\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3734\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3735\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3736\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3737\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3738\u001b[0m )\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'thres_80.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def accuracy(n_largest,match_threshold): #instead of gntm here we have PLSA or other probabilitic models\n",
    "\n",
    "    bay=cleaned_bay\n",
    "    gnt=cleaned_plsa_5 #changing the gntm to plsa\n",
    "    print(\"read sucessfully\")\n",
    "    # bay.drop([\"Unnamed: 0\"],axis=1,inplace=True) \n",
    "    # gnt.drop([\"Unnamed: 0\"],axis=1,inplace=True) \n",
    "    bay,gnt=bay.transpose(),gnt.transpose()\n",
    "    bay_top_3,gnt_top_3=[],[]\n",
    "\n",
    "    for col in range(bay.shape[1]):\n",
    "        try:\n",
    "            bay_top_3.append(bay.nlargest(n_largest,col).index) \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for col in range(gnt.shape[1]):\n",
    "        try:\n",
    "            gnt_top_3.append(gnt.nlargest(n_largest,col).index)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    bay_col_names=[]\n",
    "    gnt_col_names=[]\n",
    "    for i in range(1,n_largest+1):\n",
    "        bay_col_names.append(f'bay_top{str(i)}')\n",
    "        gnt_col_names.append(f'gnt_top{str(i)}')\n",
    "        \n",
    "    bay_top3_df=pd.DataFrame(bay_top_3,columns=bay_col_names)\n",
    "    gnt_top3_df=pd.DataFrame(gnt_top_3,columns=gnt_col_names)\n",
    "    final_matches=[]\n",
    "    for gnt_out,bay_out in zip(gnt_top_3,bay_top_3):\n",
    "        matches=[]\n",
    "        for out in gnt_out:\n",
    "            if out in bay_out:\n",
    "                matches.append(True)\n",
    "            else:\n",
    "                matches.append(False)\n",
    "        percentage_of_acc=(matches.count(True)/len(matches))*100\n",
    "        if percentage_of_acc >= match_threshold: \n",
    "            final_matches.append(True)\n",
    "        else:\n",
    "            final_matches.append(False)\n",
    "    result=pd.concat([bay_top3_df,gnt_top3_df,pd.DataFrame(final_matches,columns=[\"match\"])],axis=1)\n",
    "    # decision=str(input(\"Do you want to save the o/p(yes/no)?\"))\n",
    "    decision=\"yes\"\n",
    "    if decision==\"Yes\" or decision==\"yes\" or decision==\"YES\":\n",
    "        file_name=str(input(\"enter file name :\"))\n",
    "        result.to_csv(f\"{file_name}.csv\")\n",
    "    \n",
    "    try:\n",
    "        result[\"match\"].value_counts()[True]\n",
    "    except:\n",
    "        print('accuracy : 0 % ')\n",
    "    try:\n",
    "        result[\"match\"].value_counts()[False]\n",
    "    except:\n",
    "        print('accuracy : 100%')\n",
    "\n",
    "    try:\n",
    "        accuracy=result[\"match\"].value_counts()[True]/(result[\"match\"].value_counts()[True]+result[\"match\"].value_counts()[False])\n",
    "        print(\"The accuracy is :\",accuracy)\n",
    "    except:\n",
    "        print(\"result already shown\")\n",
    "\n",
    "\n",
    "\n",
    "topics=str(input(\"enter no. of topics :\"))\n",
    "n_largest=int(input(\"enter n_largest : \"))\n",
    "\n",
    "thres=[60,80,100]\n",
    "\n",
    "for threshold in thres:\n",
    "    print(\"topics:\",topics)\n",
    "    print(\"n largest :\",n_largest)\n",
    "    print(\"Threshold is :\",threshold)\n",
    "    accuracy(n_largest,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
